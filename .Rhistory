setwd("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data")
library(dplyr)
df1 <- read.csv("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data/DisasterDeclarationsSummaries.csv")
df2 <- read.csv("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data/HousingAssistanceOwners.csv")
str(df1)
library(dplyr)
df1 <- read.csv("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data/DisasterDeclarationsSummaries.csv")
df2 <- read.csv("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data/HousingAssistanceOwners.csv")
df1 <- df1 %>% mutate(designatedArea = gsub(" \\(county\\)", "", designatedArea))
str(df1)
df1 <- df1 %>% mutate(designatedArea = gsub(" \\(county\\)", "", designatedArea))
areas_unique <- unique(df1$designatedArea)
df1$designatedArea <- sub(" \\(County\\)", "", df1$designatedArea)
areas_unique <- unique(df1$designatedArea)
areas_unique
df1$designatedArea <- sub(" \\(Parish\\)", "", df1$designatedArea)
df1$designatedArea <- sub(" \\(Municipio\\)", "", df1$designatedArea)
areas_unique <- unique(df1$designatedArea)
areas_unique
df1$designatedArea <- sub("\\(.*", "", df1$designatedArean)
areas_unique <- unique(df1$designatedArea)
areas_unique
df1$designatedArea <- sub("\\(.*", "", df1$designatedArea)
areas_unique <- unique(df1$designatedArea)
areas_unique
df1$designatedArea <- sapply(strsplit(df1$designatedArea, "\\("), function(x) x[1])
areas_unique <- unique(df1$designatedArea)
areas_unique
#####################################try the wikipedia one
#install.packages('rvest')
library(rvest)
# Reading in the table from Wikipedia
page = read_html("https://en.wikipedia.org/wiki/List_of_United_States_counties_by_per_capita_income")
# Obtain the piece of the web page that corresponds to the "wikitable" node
my.table = html_node(page, ".wikitable")
# Convert the html table element into a data frame
my.table = html_table(my.table, fill = TRUE)
# Extracting and tidying a single column from the table and adding row names
x = as.numeric(gsub("\\[.*","",my.table[,4]))
names(x) = gsub("\\[.*","",my.table[,2])
# Excluding non-states and averages from the table
per.capita.income = x[!names(x) %in% c("United States", "Northern Mariana Islands", "Guam", "American Samoa", "Puerto Rico", "U.S. Virgin Islands")]
df2$county <- sub("\\(.*", "", df2$county)
df_merge <- merge(df1,df2,by="disasterNumber")
View(df_merge)
merge_2 <- complete.cases(df_merge)
df_merge3 <- na.omit(df_merge)
View(df_merge3)
View(df_merge)
View(df2)
View(df1)
df2$new_id <- paste(df2$disasterNumber, df2$county, sep = "")
str(df2)
df1$new_id <- paste(df1$disasterNumber, df1$designatedArea, sep = "")
###group by disasterid and county --> aggregate
grp_tbl <- df2 %>% group_by(new_id)
grp_tbl
# summarise on groupped data.
agg_tbl <- grp_tbl %>% summarise(sum(validRegistrations, averageFemaInspectedDamage, totalInspected, totalApprovedIhpAmount, repairReplaceAmount, rentalAmount, otherNeedsAmount, totalMaxGrants))
agg_tbl
View(agg_tbl)
# summarise on groupped data.
agg_tbl <- grp_tbl %>% summarise_at(vars(validRegistrations, averageFemaInspectedDamage, totalInspected, totalApprovedIhpAmount, repairReplaceAmount, rentalAmount, otherNeedsAmount, totalMaxGrants),
funs(sum))
agg_tbl
View(agg_tbl)
str(df1)
str(df2)
str(my.table)
str(agg_tbl)
setwd("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data")
library(dplyr)
library(tidyr)
df1 <- read.csv("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data/DisasterDeclarationsSummaries.csv")
df2 <- read.csv("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data/HousingAssistanceOwners.csv")
df1$designatedArea <- sub("\\(.*", "", df1$designatedArea)
df2$county <- sub("\\(.*", "", df2$county)
str(df1)
str(df2)
merge <- full_join(x = df1, y = df2, by = c('designatedArea' = 'county', 'disasterNumber' = 'disasterNumber'))
merge_id <- full_join(x = df1, y = df2, by = c('disasterNumber' = 'disasterNumber'))
merge_na <- merge_id[!with(merge_id,is.na("totalMaxGrants")& is.na("repairReplaceAmount")),]
merge_na <- merge_id
merge_neu <- merge_na %>%
filter(!if_all(c(totalMaxGrants, repairReplaceAmount), is.na))
summary(merge_neu)
merge_neuee <- merge_neu %>% drop_na()
summary(merge_neuee)
row.has.na <- apply(merge_na, 1, function(x){any(is.na(x))})
sum(row.has.na)
final.filtered <- merge_na[!row.has.na,]
row.has.na1 <- apply(final.filtered, 1, function(x){any(is.na(x))})
row.has.na1 <- apply(final.filtered, 1, function(x){any(is.na(x))})
sum(row.has.na1)
merge_i <- inner_join(x = df1, y = df2, by = c('designatedArea' = 'county', 'disasterNumber' = 'disasterNumber'))
View(merge_i)
row.has.na <- apply(merge_i, 1, function(x){any(is.na(x))})
final.filtered <- merge_i[!row.has.na,]
# Reading in the table from Wikipedia
page = read_html("https://en.wikipedia.org/wiki/List_of_United_States_counties_by_per_capita_income")
library(rvest)
page = read_html("https://en.wikipedia.org/wiki/List_of_United_States_counties_by_per_capita_income")
# Obtain the piece of the web page that corresponds to the "wikitable" node
my.table = html_node(page, ".wikitable")
# Convert the html table element into a data frame
my.table = html_table(my.table, fill = TRUE)
# Extracting and tidying a single column from the table and adding row names
x = as.numeric(gsub("\\[.*","",my.table[,4]))
names(x) = gsub("\\[.*","",my.table[,2])
# Excluding non-states and averages from the table
per.capita.income = x[!names(x) %in% c("United States", "Northern Mariana Islands", "Guam", "American Samoa", "Puerto Rico", "U.S. Virgin Islands")]
library(readxl)
UScounties <- read_excel("~/switchdrive/R-bootcamp/UScounties.xlsx")
View(UScounties)
View(merge_i)
###left join
merge_county <- left_join(x = merge_i, y = UScounties, by = c('designatedArea' = 'county''))
###left join
merge_county <- left_join(x = merge_i, y = UScounties, by = c('designatedArea' = 'county'))
View(UScounties)
###left join
merge_county <- left_join(x = merge_i, y = UScounties, by = c('designatedArea' = 'county'))
View(merge_county)
###left join
merge_county <- full_join(x = merge_i, y = UScounties, by = c('designatedArea' = 'county'))
View(merge_county)
View(merge_county)
View(merge_county)
UScounties$county <- sub("\\(.*", "", UScounties$county)
###left join
merge_county <- full_join(x = merge_i, y = UScounties, by = c('designatedArea' = 'county'))
View(merge_county)
View(df1)
View(df2)
merge_i %>%
select(designatedArea, zipCode)
merge_i %>%
select(designatedArea, zipCode) %>%
as_tibble()
UScounties %>%
select(county, county_ascii) %>%
as_tibble()
library(stringr)
str_remove(string = "asdf   ", pattern = " +$")
o
str_remove(string = merge_i$designatedArea, pattern = " +$")
###left join
merge_county <- left_join(x = merge_i, y = UScounties, by = c('designatedArea' = 'county'))
View(merge_county)
merge_i %>%
select(designatedArea, zipCode) %>%
as_tibble()
merge_i$designatedArea <- str_remove(string = merge_i$designatedArea, pattern = " +$")
merge_i %>%
select(designatedArea, zipCode) %>%
as_tibble()
merge_i %>%
select(designatedArea, zipCode) %>%
as_tibble()
merge_i %>%
select(designatedArea, zipCode) %>%
as_tibble()
###left join
merge_county <- left_join(x = merge_i, y = UScounties, by = c('designatedArea' = 'county'))
View(merge_county)
View(my.table)
View(merge_county)
library(tidyverse)
my.table %>%
rename(
county = County or `County or county-equivalent`
my.table %>%
rename(
county = `County or County or county-equivalent`
)
my.table %>%
rename(
county = `County or county-equivalent`
)
###left join
merge_capita <- left_join(x = merge_county, y = my.table, by = c('designatedArea' = 'county'))
my.table %>%
rename(
county = `County or county-equivalent`
)
my.table <- my.table %>%
rename(
county = `County or county-equivalent`
)
###left join
merge_capita <- left_join(x = merge_county, y = my.table, by = c('designatedArea' = 'county'))
View(merge_capita)
###left join
merge_county <- left_join(x = merge_i, y = UScounties, by = c('designatedArea' = 'county', 'state_x' = 'state_name'))
##EINLESEN
df1 <- read.csv("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data/DisasterDeclarationsSummaries.csv")
df2 <- read.csv("/Users/milicapajkic/Documents/GitHub/bootcamp_r/Data/HousingAssistanceOwners.csv")
UScounties <- read_excel("~/switchdrive/R-bootcamp/UScounties.xlsx")
# Reading in the table from Wikipedia
page = read_html("https://en.wikipedia.org/wiki/List_of_United_States_counties_by_per_capita_income")
# Obtain the piece of the web page that corresponds to the "wikitable" node
my.table = html_node(page, ".wikitable")
# Convert the html table element into a data frame
my.table = html_table(my.table, fill = TRUE)
# Extracting and tidying a single column from the table and adding row names
x = as.numeric(gsub("\\[.*","",my.table[,4]))
names(x) = gsub("\\[.*","",my.table[,2])
# Excluding non-states and averages from the table
per.capita.income = x[!names(x) %in% c("United States", "Northern Mariana Islands", "Guam", "American Samoa", "Puerto Rico", "U.S. Virgin Islands")]
my.table <- my.table %>%
rename(
county = `County or county-equivalent`
)
df1$designatedArea <- sub("\\(.*", "", df1$designatedArea)
df2$county <- sub("\\(.*", "", df2$county)
UScounties$county <- sub("\\(.*", "", UScounties$county)
merge_i <- inner_join(x = df1, y = df2, by = c('designatedArea' = 'county', 'disasterNumber' = 'disasterNumber'))
merge_i$designatedArea <- str_remove(string = merge_i$designatedArea, pattern = " +$")
str_extract(string = , pattern = "")
